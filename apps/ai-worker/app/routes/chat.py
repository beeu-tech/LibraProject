from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import Optional, List
import json
import structlog
import asyncio

from ..services.groq_service import GroqService
from ..services.memory_service import MemoryService
from ..services.prompt_service import PromptService

logger = structlog.get_logger()
router = APIRouter()

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ - Groq APIë§Œ ì‚¬ìš©
groq_service = GroqService()
memory_service = MemoryService()
prompt_service = PromptService()

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœ
_services_initialized = False

async def ensure_services_initialized():
    """ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ì´ˆê¸°í™”"""
    global _services_initialized
    if not _services_initialized:
        try:
            print("[Chat] ğŸŒ©ï¸ Groq API ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘")
            await groq_service.initialize()
            await memory_service.initialize()
            await prompt_service.initialize()
            _services_initialized = True
            print("[Chat] âœ… Groq API ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"[Chat] âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise

class ChatRequest(BaseModel):
    # Bot í˜¸í™˜ì„±ì„ ìœ„í•´ contentì™€ messages ëª¨ë‘ Optional
    content: Optional[str] = Field(None, description="ë©”ì‹œì§€ ë‚´ìš© (Bot í˜•ì‹)")
    messages: Optional[List[dict]] = Field(None, description="ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ (í‘œì¤€ í˜•ì‹)")
    userId: str = Field(..., description="ì‚¬ìš©ì ID")
    username: str = Field(..., description="ì‚¬ìš©ìëª…")
    channelId: str = Field(..., description="ì±„ë„ ID")
    guildId: Optional[str] = Field(None, description="ê¸¸ë“œ ID")
    messageId: str = Field(..., description="ë©”ì‹œì§€ ID")

@router.post("/chat/completions")
async def chat_completions(request: ChatRequest):
    """Groq APIë¥¼ í†µí•œ ì±„íŒ… ì™„ì„±"""
    try:
        # Bot í˜•ì‹ (content)ê³¼ í‘œì¤€ í˜•ì‹ (messages) ëª¨ë‘ ì§€ì›
        user_message = ""
        if request.content:
            # Bot í˜•ì‹: content í•„ë“œ ì‚¬ìš©
            user_message = request.content
        elif request.messages and len(request.messages) > 0:
            # í‘œì¤€ í˜•ì‹: messages ë°°ì—´ ì‚¬ìš©
            user_message = request.messages[-1].get("content", "")
        else:
            raise HTTPException(status_code=400, detail="content ë˜ëŠ” messages í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        print("=== AI Worker ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨ ===")
        print(f"ì‚¬ìš©ì: {request.username} ({request.userId})")
        print(f"ë©”ì‹œì§€: {user_message}")
        print(f"ì±„ë„: {request.channelId}")
        print("=====================================")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í™•ì¸
        await ensure_services_initialized()
        
        # ë©”ì‹œì§€ ì €ì¥
        await memory_service.save_message(
            user_id=request.userId,
            username=request.username,
            channel_id=request.channelId,
            content=user_message,
            message_id=request.messageId
        )
        
        # ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
        conversation = await memory_service.get_conversation(
            user_id=request.userId,
            channel_id=request.channelId,
            limit=10
        )
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = await prompt_service.get_system_prompt()
        
        # ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„± (system â†’ ê³¼ê±° ëŒ€í™” â†’ í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€)
        messages = [{"role": "system", "content": system_prompt}]
        
        # ê³¼ê±° ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
        if conversation:
            messages.extend(conversation)
        
        # âœ… í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (ì´ê²Œ í•µì‹¬!)
        messages.append({"role": "user", "content": user_message})
        
        print(f"[Stream] ğŸ“¨ ë©”ì‹œì§€ êµ¬ì„± ì™„ë£Œ: {len(messages)}ê°œ ë©”ì‹œì§€")
        print(f"[Stream] ì‹œìŠ¤í…œ: 1ê°œ, íˆìŠ¤í† ë¦¬: {len(conversation)}ê°œ, í˜„ì¬: 1ê°œ")
        print(f"[Stream] ì‚¬ìš©ì ì§ˆë¬¸: {user_message[:100]}")
        
        # ë””ë²„ê¹…: ì „ì²´ ë©”ì‹œì§€ ì¶œë ¥
        print("\n=== Groqì— ì „ë‹¬ë˜ëŠ” ì „ì²´ ë©”ì‹œì§€ ===")
        for i, msg in enumerate(messages):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')[:100]
            print(f"{i+1}. [{role}] {content}")
        print("=" * 50 + "\n")
        
        print("[Stream] ğŸš€ Groq API ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
        
        async def generate_response():
            try:
                chunk_count = 0
                full_response = ""  # AI ì‘ë‹µ ì „ì²´ ëˆ„ì 
                
                async for chunk in groq_service.stream_response(messages, request.channelId):
                    chunk_count += 1
                    print(f"[Stream] ì²­í¬ #{chunk_count}: error={chunk.get('error')}, content={chunk.get('content')[:20] if chunk.get('content') else None}, finished={chunk.get('finished')}")
                    
                    if chunk.get("error"):
                        yield f"data: {json.dumps({'error': chunk['error']})}\n\n"
                        break
                    
                    if chunk.get("content"):
                        content = chunk['content']
                        
                        # <think> íƒœê·¸ í•„í„°ë§ (Qwen ëª¨ë¸ ì¶”ë¡  ê³¼ì • ì œê±°)
                        if '<think>' in full_response or '<think>' in content:
                            full_response += content
                            # <think> íƒœê·¸ ì•ˆì˜ ë‚´ìš©ì€ ì „ì†¡í•˜ì§€ ì•ŠìŒ
                            if '</think>' in full_response:
                                # íƒœê·¸ ì¢…ë£Œ í›„ë¶€í„°ë§Œ ì „ì†¡
                                parts = full_response.split('</think>')
                                if len(parts) > 1:
                                    clean_content = parts[-1]
                                    full_response = clean_content
                                    if clean_content.strip():
                                        yield f"data: {json.dumps({'content': clean_content})}\n\n"
                            continue
                        
                        full_response += content  # ì‘ë‹µ ëˆ„ì 
                        yield f"data: {json.dumps({'content': content})}\n\n"
                    
                    if chunk.get("finished"):
                        print(f"[Stream] âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: ì´ {chunk_count}ê°œ ì²­í¬, ì‘ë‹µ ê¸¸ì´: {len(full_response)}")
                        
                        # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                        if full_response.strip():
                            await memory_service.save_message(
                                user_id=request.userId,
                                username="assistant",
                                channel_id=request.channelId,
                                content=full_response,
                                message_id=f"{request.messageId}_response",
                                role="assistant"
                            )
                        
                        yield f"data: {json.dumps({'finished': True})}\n\n"
                        break
                        
            except Exception as e:
                logger.error("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨", error=str(e))
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
        
        return StreamingResponse(
            generate_response(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )
        
    except Exception as e:
        logger.error("ì±„íŒ… ì™„ì„± ì‹¤íŒ¨", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))
